#!/usr/bin/env python

import logging
log = logging.getLogger('alpaca')
log.setLevel(logging.DEBUG)
fh = logging.FileHandler('alpaca.log')
fh.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
ff = logging.Formatter('[%(asctime)s] %(levelname)s :: %(message)s')
cf = logging.Formatter('[%(levelname)s] %(message)s')
fh.setFormatter(ff)
ch.setFormatter(cf)
log.addHandler(fh)
log.addHandler(ch)

from pathlib import Path
import datetime

import uproot
import uproot_methods
import awkward
import numpy as np
import matplotlib.pyplot as plt
import torch
from sklearn.metrics import roc_curve, auc
from progressbar import progressbar

from collections import defaultdict

from alpaca.colalola import CoLaLoLa


class BatchManager:

    def __init__(self, sig_path, bkg_path):
        self._sig_lv = self.get_lorentz_vectors(sig_path)
        self._bkg_lv = self.get_lorentz_vectors(bkg_path)
        log.info('Nr. of signal events: %s', len(self._sig_lv))
        log.info('Nr. of background events: %s', len(self._bkg_lv))
 
    @staticmethod
    def get_lorentz_vectors(file_path):
        """
        The returned object looks like this:
        
        [[[event 1 jet 1 t, event 1 jet 1 x, event 1 jet 1 y, event 1 jet 1 z]
          [event 1 jet 2 t, event 1 jet 2 x, event 1 jet 2 y, event 1 jet 2 z]
          [event 1 jet 3 t, event 1 jet 3 x, event 1 jet 3 y, event 1 jet 3 z]
          [event 1 jet 4 t, event 1 jet 4 x, event 1 jet 4 y, event 1 jet 4 z]
          [event 1 jet 5 t, event 1 jet 5 x, event 1 jet 5 y, event 1 jet 5 z]
          [event 1 jet 6 t, event 1 jet 6 x, event 1 jet 6 y, event 1 jet 6 z]]
          [[event 2 jet 1 t, event 2 jet 1 x, event 2 jet 1 y, event 1 jet 1 z]
          [event 2 jet 2 t, event 2 jet 2 x, event 2 jet 2 y, event 1 jet 2 z]
           ...

        basically they are separated by events. For each event they are
        separated by jet: jet 1, jet 2, etc. And for each jet the four elements
        are the four coordinates of the TLorentz vector: t, x, y, z.
        """
        nominal = uproot.open(str(file_path))['nominal']
        arrays = nominal.arrays(
            ['reco_bjets', 'jet_pt', 'jet_eta', 'jet_phi', 'jet_e', 'jet_n',
             'reco_index_w[12]j[ab]', 'reco_index_b[12]',
             'reco_Chi2Fitted', 'reco_DRbWMax', 'reco_DRbb',
             'reco_t[12]_m'],
            namedecode='ascii'
        )

        N_jets = 10

        for i in range(len(arrays['jet_pt'])):
            for a,b in zip(arrays['jet_pt'][i][:-1], arrays['jet_pt'][i][1:]):
                if a < b:
                    print('Bau: {} < {}'.format(a, b))
            for lbl in ['jet_pt', 'jet_eta', 'jet_phi', 'jet_e']:
                for _ in range(N_jets - len(new_arrays[lbl][-1])):
                    new_arrays[lbl][-1].append(0)

        new_arrays = defaultdict(list)
        for i in range(len(arrays['jet_pt'])):
           index_w1ja = arrays['reco_index_w1ja'][i]
           index_w2ja = arrays['reco_index_w2ja'][i]
           index_w1jb = arrays['reco_index_w1jb'][i]
           index_w2jb = arrays['reco_index_w2jb'][i]
           index_b1 = arrays['reco_index_b1'][i]
           index_b2 = arrays['reco_index_b2'][i]

           extras = list(range(len(arrays['jet_pt'][i])))
           extras.remove(index_w1ja)
           extras.remove(index_w1jb)
           extras.remove(index_w2ja)
           extras.remove(index_w2jb)
           extras.remove(index_b1)
           extras.remove(index_b2)
           for lbl in ['jet_pt', 'jet_eta', 'jet_phi', 'jet_e']:
               new_arrays[lbl].append([
                   arrays[lbl][i][index_w1ja],
                   arrays[lbl][i][index_w1jb],
                   arrays[lbl][i][index_b1],
                   arrays[lbl][i][index_w2ja],
                   arrays[lbl][i][index_w2jb],
                   arrays[lbl][i][index_b2],
               ])
               # TODO: add the leading extra jets
               for index_extra in extras[:N_jets - 6]:
                   new_arrays[lbl][-1].append(arrays[lbl][i][index_extra])
               for _ in range(N_jets - len(new_arrays[lbl][-1])):
                   new_arrays[lbl][-1].append(0)

        table = awkward.Table(
            pt=awkward.fromiter(new_arrays['jet_pt']),
            eta=awkward.fromiter(new_arrays['jet_eta']),
            phi=awkward.fromiter(new_arrays['jet_phi']),
            e=awkward.fromiter(new_arrays['jet_e'])
        )

        lor_vec = uproot_methods.TLorentzVectorArray.from_ptetaphi(
            table.pt,
            table.eta,
            table.phi,
            table.e
        )

        lor_vec_stack = np.stack(
            [lor_vec.t.regular(),
             lor_vec.x.regular(),
             lor_vec.y.regular(),
             lor_vec.z.regular()],
            axis=-1
        )

        return lor_vec_stack

    def get_torch_batch(self, N, start_index=0):
        stop_index = start_index + N
        if stop_index > min(len(self._sig_lv), len(self._bkg_lv)):
            log.warning('The stop index is grater than the size of the array')
        lv = np.concatenate([self._sig_lv[start_index:stop_index],
                             self._bkg_lv[start_index:stop_index]])
        scores = np.concatenate([np.ones(N), np.zeros(N)])

        X = torch.as_tensor(lv, dtype=torch.float)
        Y = torch.as_tensor(scores, dtype=torch.float)
        return X, Y


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='ML top-like tagger.')
    parser.add_argument('--bkg', required=True, type=Path,
                        help='path to the file with bkg events')
    parser.add_argument('--sig', required=True, type=Path,
                        help='path to the file with sig events')
    parser.add_argument('--quick-test', action='store_true',
                        help='set params for a quick test')
    parser.add_argument('--output-dir', type=Path, default=Path('data'),
                        help='path to the output directory')
    parser.add_argument('--tag', nargs='?', const='',
                        help='tag the output')
    args = parser.parse_args()

    if args.quick_test:
        args.tag = 'test'

    output_dir = args.output_dir
    if args.tag is not None:
        now = datetime.datetime.now()
        if args.tag:
            new_dir_name = '{:%Y%m%d_%H%M%S}_{}'.format(now, args.tag)
        else:
            new_dir_name = '{:%Y%m%d_%H%M%S}'.format(now)
        output_dir = output_dir / new_dir_name
        output_dir.mkdir(parents=True, exist_ok=True)

        nfh = logging.FileHandler(str(output_dir / 'alpaca.log'))
        nfh.setLevel(logging.DEBUG)
        nfh.setFormatter(ff)
        log.addHandler(nfh)

    output_dir.mkdir(parents=True, exist_ok=True)

    log.debug('Signal input: %s', args.sig)
    log.debug('Background input: %s', args.bkg)
    bm = BatchManager(sig_path=args.sig, bkg_path=args.bkg)

    nobjects = 10#6
    ncombos = 30
    log.debug('CoLaLoLa: nr. jets %s - nr. combos %s', nobjects, ncombos)
    model = CoLaLoLa(nobjects, ncombos)
    opt = torch.optim.Adam(model.parameters())
    losses = []

    nr_train = 190
    batch_size = 350
    if args.quick_test:
        nr_train = 5
        batch_size = 500
    log.debug('Training: %s iterations - batch size %s', nr_train, batch_size)
    for i in progressbar(range(nr_train)):
        model.train()
        opt.zero_grad()

        X, Y = bm.get_torch_batch(batch_size, start_index=i * batch_size)
        P, masses = model(X)
        P, Y = P, Y.reshape(-1, 1)

        loss = torch.nn.functional.binary_cross_entropy(P, Y)
        losses.append(float(loss))
        #if i % 25 == 0:
        #    print(loss)
        #    #plt.plot(losses)
        #    #plt.show()
        loss.backward()
        opt.step()

    log.debug('Finished training')
    fig = plt.figure()
    plt.plot(losses)
    plt.savefig(str(output_dir / 'losses.png'))

    log.info('Save plot model')
    fig = plt.figure()
    plt.imshow(model.cola.w_combo.data.numpy())
    plt.savefig(str(output_dir / 'w_combo.png'))

    log.info('Make torch batch')
    X,Y = bm.get_torch_batch(5000, nr_train * batch_size)
    P, masses_sig = model(X)
    _P = P.data.numpy()
    _Y = Y.data.numpy()

    #X,Y = bm.get_torch_batch(5000, nr_train * batch_size)
    #X, Y = X[:5000], Y[:5000]
    #P, masses_bkg = model(X)
    #_P = P.data.numpy()
    #_Y = Y.data.numpy()

    #log.info('Plot mass histogram')
    #fig = plt.figure()

    #bins = np.linspace(0, 6000, 50)
    #plt.hist(np.sqrt(np.abs(masses_bkg)) / 1000., bins=bins, histtype='step',
    #         label='bkg')
    #plt.hist(np.sqrt(np.abs(masses_sig)) / 1000., bins=bins, histtype='step',
    #         label='signal')
    #plt.yscale('log')
    #plt.xscale('log')
    #plt.xlabel('Mass [GeV]')
    #plt.legend()
    #plt.savefig(str(output_dir / 'masses.png'))

    log.info('Feature Histogram')
    _X = X.data.numpy()
    pts = []
    for i, score in enumerate(P):
        if score > -1:
            jets_lv = []
            for jet_coo in _X[i]:
                lv = uproot_methods.TLorentzVector(x=jet_coo[1],
                                                   y=jet_coo[2],
                                                   z=jet_coo[3],
                                                   t=jet_coo[0])
                jets_lv.append(lv)
            jets_lv.sort(key=lambda x: x.pt, reverse=True)
            pts.append(jets_lv[0].pt / 1000.)

    fig = plt.figure()
    plt.hist(pts, bins=1000, label='score > -1')
    plt.xlabel('Leading Jet PT [GeV]')
    plt.legend()
    plt.savefig(str(output_dir / 'leading_pt.png'))


    log.info('Plot Histograms')
    fig = plt.figure()
    plt.hist(_P[_Y==0],
             bins = np.linspace(0, 1, 510),
             label='bkg',
             density=True,
             histtype='step')
    plt.hist(_P[_Y==1],
             bins = np.linspace(0, 1, 510),
             density=True,
             label='sig',
             histtype='step')
    #plt.semilogy()
    plt.legend()
    plt.savefig(str(output_dir / 'score.png'))

    log.info('Plot ROC curve')
    fpr, tpr, thr = roc_curve(_Y, _P)
    roc_auc = auc(fpr, tpr)
    #print(len(fpr))
    #print(max(fpr))
    #print(fpr[-10:])
    #print(len(_P))

    fig = plt.figure()
    plt.plot(fpr, tpr, color='darkorange',
             label='ROC curve (area = {:.2f})'.format(roc_auc))
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    #plt.title('Receiver operating characteristic')
    plt.legend(loc="lower right")
    plt.savefig(str(output_dir / 'roc_curve.png'))

    w = model.cola.w_combo.data.numpy()
    fig = plt.figure()
    plt.hist(X.data.numpy()[Y==0, :, 1].ravel(), bins=100)

    plt.savefig(str(output_dir / 'ravel.png'))

    X.data.numpy()[Y==0, :, 1]

    #log.info('Make torch batch')
    #X, Y = bm.get_torch_batch(500, nr_train * batch_size)
    #np.unique(X[Y==1].data.numpy()[:, :, 0].ravel()).shape
    #fig = plt.figure()
    #_,b,_ = plt.hist(X[Y==1].data.numpy()[:, :, 0].ravel(),bins=100);
    #plt.hist(X[Y==0].data.numpy()[:, :, 0].ravel(),bins=b);
    #plt.savefig('data/ravel_2.png')
