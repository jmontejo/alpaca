#!/usr/bin/env python

import logging

from pathlib import Path
import datetime

import numpy as np
import torch
from progressbar import progressbar

import matplotlib.pyplot as plt

import alpaca.log
from alpaca.batch import BatchManager

logging.getLogger('matplotlib').setLevel(logging.WARNING)

log = logging.getLogger(__name__)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='ML top-like tagger.')
    parser.add_argument('--sig', required=True, type=Path,
                        help='path to the file with sig events')
    parser.add_argument('--quick-test', action='store_true',
                        help='set params for a quick test')
    parser.add_argument('--output-dir', type=Path, default=Path('data'),
                        help='path to the output directory')
    parser.add_argument('--tag', default='alpaca',
                        help='tag the output')
    parser.add_argument('--shuffle-jets', action='store_true',
                        help='reorder jets in each event')
    parser.add_argument('--shuffle-events', action='store_true',
                        help='reorder events in the dataset')
    parser.add_argument('--simple-nn', action='store_true',
                        help=('substitute a simple feed-forward NN for '
                              'colalola'))
    parser.add_argument('--hydra', action='store_true',
                        help='a colalola network with multiple output heads')
    parser.add_argument('--alt-loss', action='store_true',
                        help='try a different loss function')
    parser.add_argument("--fflayers", nargs="+", type=int, default=[200])
    parser.add_argument("--ncombos", type=int, default=30)
    args = parser.parse_args()

    if args.quick_test:
        args.tag = 'test'

    # Autogenerate meaningful names for output dir
    output_dir = args.output_dir
    new_dir_name = args.tag
    if args.shuffle_jets:
        new_dir_name += "_shuffled"
    else:
        new_dir_name += "_ptordered"
    if args.simple_nn:
        new_dir_name += "_simplenn"
    elif args.hydra:
        new_dir_name += "_hydra"
    if args.alt_loss:
        new_dir_name += "_altloss"
    new_dir_name += "_{}combos".format(args.ncombos)
    layerstr = '_'.join([str(i) for i in args.fflayers])
    new_dir_name += "_" + layerstr

    output_dir = output_dir / new_dir_name
    output_dir.mkdir(parents=True, exist_ok=True)

    alpaca.log.setup_logger(file_path=output_dir / 'alpaca.log')
    log.debug('Alpaca has been started and can finally log')

    log.info('Writing to dir: %s', new_dir_name)

    log.debug('Signal input: %s', args.sig)
    njets = 7
    bm = BatchManager(
        sig_path=args.sig,
        shuffle_jets=args.shuffle_jets,
        shuffle_events=args.shuffle_events,
        jets_per_event=njets,
        zero_jets=10-njets
    )

    nobjects = njets
    ntomatch = 5
    ntobtag = 6
    noutputs = njets + ntomatch + ntobtag
    if args.simple_nn:
        from alpaca.simple import SimpleNN
        log.info('SimpleNN: nr. jets %s', nobjects)
        log.info('  FeedForwardHead intermediate layers: [%s]',
                 layerstr.replace('_', ','))
        model = SimpleNN(nobjects, noutputs, fflayers=args.fflayers)
    elif args.hydra:
        from alpaca.hydra import Hydra
        log.info('CoLaLoLa with multiple heads: nr. jets %s - nr. combos %s',
                 nobjects, args.ncombos)
        log.info('  FeedForwardHead intermediate layers: [%s]',
                 layerstr.replace('_', ','))
        model = Hydra(nobjects, args.ncombos, fflayers=args.fflayers)
    else:
        # Plain CoLaLoLa as default
        from alpaca.colalola import CoLaLoLa
        log.info('CoLaLoLa: nr. jets %s - nr. combos %s', nobjects,
                 args.ncombos)
        log.info('  FeedForwardHead intermediate layers: [%s]',
                 layerstr.replace('_', ','))
        model = CoLaLoLa(nobjects, args.ncombos, noutputs,
                         fflayers=args.fflayers)

    opt = torch.optim.Adam(model.parameters())
    losses = {"total": [], "ISR": [], "decay": [], "bjet": []}
    if args.alt_loss:
        losses.update({"penalty_ISR": [], "penalty_decay": []})

    nr_train = 250
    batch_size = 250
    # No stats right now
    if args.quick_test:
        nr_train = 100
        batch_size = 100
    log.debug('Training: %s iterations - batch size %s', nr_train, batch_size)
    for i in progressbar(range(nr_train)):
        model.train()
        opt.zero_grad()

        X, Y = bm.get_torch_batch(batch_size, nlabels=njets,
                                  start_index=i * batch_size + 5000)
        P = model(X)
        Y = Y.reshape(-1, noutputs)
        P_ISR, Y_ISR = P[:, :njets], Y[:, :njets]
        P_decay, Y_decay = P[:, njets:njets+5], Y[:, njets:njets+5]
        P_bjet, Y_bjet = P[:, njets+5:], Y[:, njets+5:]

        loss = {
            "ISR": torch.nn.functional.binary_cross_entropy(P_ISR, Y_ISR),
            "decay": torch.nn.functional.binary_cross_entropy(P_decay, Y_decay),
            "bjet": torch.nn.functional.binary_cross_entropy(P_bjet, Y_bjet),
        }
        loss["total"] = loss["ISR"] + loss["decay"] + loss["bjet"]
        if args.alt_loss:
            loss["penalty_ISR"] = P_ISR[Y_ISR == 0].mean() + \
                                  (1 - P_ISR[Y_ISR == 1]).mean()
            loss["penalty_decay"] = P_decay[Y_decay == 0].mean() + \
                                    (1 - P_decay[Y_decay == 1]).mean()
            loss["total"] += loss["penalty_ISR"] + loss["penalty_decay"]

        for key, val in loss.items():
            losses[key].append(float(val))
        loss["total"].backward()
        opt.step()

    log.debug('Finished training')
    fig = plt.figure()
    for losstype, lossvals in losses.items():
        plt.plot(lossvals, label=losstype)
    plt.legend()
    plt.savefig(str(output_dir / 'losses.png'))

    pred = {"ISR": {}, "ttbar": {}, "bjet": {}}
    truth = {"ISR": {}, "ttbar": {}, "bjet": {}}
    jets = {}

    def fill_arrays(batch, label, model, filter_6j=False):
        X, Y = batch
        if filter_6j:
            mask = (X[:, :, 3] > 0).sum(1) == 6
            nsel = np.count_nonzero(mask)
            X = X[mask].reshape(nsel, X.shape[1], X.shape[2])
            Y = Y[mask].reshape(nsel, Y.shape[1])

        x = X.data.numpy()
        jets[label] = x
        #
        y = Y.data.numpy()
        p = model(X).data.numpy()
        # Alternatively, can split up the model output
        pred["ISR"][label] = p[:, :njets]
        pred["ttbar"][label] = p[:, njets:njets+5]
        pred["bjet"][label] = p[:, njets+5:]
        #
        truth["ISR"][label] = y[:, :njets]
        truth["ttbar"][label] = y[:, njets:njets+5]
        truth["bjet"][label] = y[:, njets+5:]

    log.info('Extracting test sample')
    fill_arrays(
        bm.get_torch_batch(
            5000,
            nlabels=njets,
            start_index=(nr_train*batch_size)+5000
        ),
        "Test",
        model
    )
    log.info(len(jets["Test"]))
    log.info('Sampling predictions for training sample')
    fill_arrays(
        bm.get_torch_batch(
            5000,
            nlabels=njets,
            start_index=5000
        ),
        "Train",
        model
    )
    log.info(len(jets["Train"]))

    bm_6j = BatchManager(
        sig_path=args.sig,
        shuffle_jets=args.shuffle_jets,
        shuffle_events=args.shuffle_events,
        jets_per_event=njets,
        zero_jets=4
    )
    log.info('Extracting sample of events with exactly 6 jets')
    # sample from the last events of the 39k 6-jet events
    fill_arrays(
        bm_6j.get_torch_batch(
            1500,
            nlabels=njets,
            start_index=0
        ),
        "6-jet",
        model
    )
    log.info(len(jets["6-jet"]))

    # Flatten & save numpy arrays
    flatdict = {}
    for sample in ["Test", "Train", "6-jet"]:
        flatdict["jets_{}".format(sample)] = jets[sample]
        for discr in ["ISR", "ttbar", "bjet"]:
            flatdict["pred_{}_{}".format(discr, sample)] = pred[discr][sample]
            flatdict["truth_{}_{}".format(discr, sample)] = truth[discr][sample]
    np.savez(str(output_dir / "data.npz"), **flatdict)

    from alpaca.plot import *
    log.info('Plot combination weights')
    if args.simple_nn:
        # No cola plots
        pass
    elif args.hydra:
        plot_hydra_weights(model, output_dir)
    else:
        plot_cola_weights(model, output_dir)

    log.info('Plot scores and ROC curves for top/tbar matching')
    plot_score_roc(
        pred,
        truth,
        "ttbar",
        output_dir,
        plotlabels=("Same decay as leading", "Different decay from leading"),
        irange=range(5)
    )

    log.info('Plot scores and ROC curves for b-jet identification')
    plot_score_roc(
        pred,
        truth,
        "bjet",
        output_dir,
        plotlabels=("b-jet", "W decay jet"),
        irange=range(6)
    )

    log.info('Plot scores for jets from tops 1 and 2')
    plot_topmatch(pred, truth, output_dir)
    if njets > 6:
        log.info('Plot scores and ROC curves for ISR-tagging')
        plot_score_roc(
            pred,
            truth,
            "ISR",
            output_dir,
            plotlabels=("Top jet", "ISR jet"),
            irange=range(njets)
        )

        log.info('Plot score for true ISR jet')
        plot_true_ISR(pred, truth, output_dir)

        log.info('Plot index of ISR jet')
        plot_index_ISR(pred, truth, output_dir)
